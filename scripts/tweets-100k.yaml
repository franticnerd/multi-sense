data_dir: &DIR ../data/tweets-100k/

# preprocessing
raw_data_file: /shared/data/czhang82/source/sample-tweets-100k/clean/tweets.txt
grid_list: [50, 50]
train_ratio: 0.9
min_token_freq: 20

# training
train_data_file: !join [*DIR, input/train.txt]
test_data_file: !join [*DIR, input/test.txt]
x_vocab_file: !join [*DIR, input/words.txt]
y_vocab_file: !join [*DIR, input/locations.txt]
train_log_file: !join [*DIR, output/train_log.txt]
performance_file:  !join [*DIR, output/performance.txt]

n_sense: 2
embedding_dim: 5
n_epoch: 200

# model_type_list: ['cbow', 'attn_net', 'sense_net', 'attn_sense_net', 'comp_attn_sense_net']
model_type_list: ['sense_net', 'attn_sense_net', 'comp_attn_sense_net']
# model_type_list: ['cbow']
