data_dir: &DIR ../data/tweets-10k/

# preprocessing
raw_data_file: /Users/chao/data/source/tweets-10k/clean/tweets.txt
grid_list: [50, 50]
train_ratio: 0.7
valid_ratio: 0.1
min_token_freq: 10

# training
train_data_file: !join [*DIR, input/train.txt]
test_data_file: !join [*DIR, input/test.txt]
valid_data_file: !join [*DIR, input/test.txt]
x_vocab_file: !join [*DIR, input/words.txt]
y_vocab_file: !join [*DIR, input/locations.txt]
train_log_file: !join [*DIR, output/train_log.txt]
performance_file:  !join [*DIR, output/performance.txt]
model_path: !join [*DIR, model/]
case_seed_file: !join [*DIR, input/case_seeds.txt]
case_output_file: !join [*DIR, output/case_outputs.txt]

load_model: False
save_model: True
data_worker: 4
n_sense: 2
embedding_dim: 50
batch_size: 4
n_epoch: 100
print_gap: 500
learning_rate: 0.01
K: 10


eval_dim: True
# dim_list: [2, 5, 10, 15, 20, 50, 100]
dim_list: [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 150, 200]

eval_batch: False
batch_list: [1, 2, 4, 8, 16, 32]

eval_lr: False
lr_list: [0.005, 0.01, 0.02, 0.05, 0.1]

# model_type_list: ['recon', 'attn', 'sense', 'attn_sense', 'comp_attn_sense', 'bilinear_sense', 'bidirection_sense']
# model_type_list: ['recon', 'sense', 'comp_attn_sense', 'bilinear_sense']
model_type_list: ['recon']

